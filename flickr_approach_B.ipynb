{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "23271202",
   "metadata": {},
   "source": [
    "Retrieving information via flickr api\n",
    "---\n",
    "\n",
    "https://www.flickr.com/services/api/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa756da1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import flickrapi\n",
    "import webbrowser\n",
    "import json\n",
    "import pandas as pd\n",
    "\n",
    "f = open(\"credentials.json\")\n",
    "creds = json.load(f)\n",
    "API_KEY = creds[\"API_KEY\"]\n",
    "API_SECRET = creds[\"API_SECRET\"]\n",
    "USER_OF_INTEREST = creds[\"USER_OF_INTEREST\"]\n",
    "OWN_USER = creds[\"OWN_USER\"]\n",
    "\n",
    "flickr = flickrapi.FlickrAPI(API_KEY, API_SECRET, format='parsed-json')\n",
    "\n",
    "# Only do this if we don't have a valid token already\n",
    "if not flickr.token_valid(perms='read'):\n",
    "\n",
    "    # Get a request token\n",
    "    flickr.get_request_token(oauth_callback='oob')\n",
    "\n",
    "    # Open a browser at the authentication URL\n",
    "    authorize_url = flickr.auth_url(perms='read')\n",
    "    webbrowser.open_new_tab(authorize_url)\n",
    "\n",
    "    # Get the verifier code from the user\n",
    "    verifier = str(input('Verifier code: '))\n",
    "\n",
    "    # Trade the request token for an access token\n",
    "    flickr.get_access_token(verifier)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7802882e",
   "metadata": {},
   "source": [
    "# Step 1: Get the IDs of a large pool of photos\n",
    "**not yet labeled**\n",
    "\n",
    "we choose to use the photos in the user's group\n",
    "\n",
    "Function: **flickr.people.getPublicGroups**\n",
    "\n",
    "**GO STRAIGHT TO STEP 3, IF YOU HAVE THIS INFORMATION ALREADY IN A CSV FILE**\n",
    "\n",
    "## A) Get IDs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe538ab6",
   "metadata": {},
   "outputs": [],
   "source": [
    "groups = flickr.people.getPublicGroups(user_id=USER_OF_INTEREST)\n",
    "groups = [(group[\"nsid\"],group[\"name\"]) for group in groups[\"groups\"][\"group\"]]\n",
    "print(\"found\",len(groups),\"groups\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b13a499",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "group_photos = {}\n",
    "\n",
    "for group_id,group_name in groups:\n",
    "    \n",
    "    try:\n",
    "        flickr.photos.search(group_id = group_id, per_page=1, page=1)\n",
    "        \n",
    "        print(group_name)\n",
    "    \n",
    "        for page in range (1,100): #limit to 99 pages\n",
    "\n",
    "            try:\n",
    "                len_before = len(group_photos.get(group_id))\n",
    "            except:\n",
    "                len_before = 0\n",
    "\n",
    "            result = flickr.photos.search(group_id = group_id, per_page=500, page=page,content_type=1 ,privacy_filter=1)\n",
    "            found_photos = [(photo[\"owner\"],photo[\"id\"]) for photo in result[\"photos\"][\"photo\"] if ((photo[\"owner\"],photo[\"id\"]) not in group_photos) & (photo[\"ispublic\"] == 1)]\n",
    "\n",
    "            if len_before == 0:\n",
    "                group_photos[group_id] = found_photos\n",
    "            else:\n",
    "                group_photos[group_id] = group_photos.get(group_id) + found_photos\n",
    "\n",
    "            len_after = len(group_photos.get(group_id))\n",
    "            \n",
    "            print(\"page:\",page,\", photos:\",len_after)\n",
    "\n",
    "            if len_after == len_before:\n",
    "                break\n",
    "\n",
    "        print(group_name,\"=>\",len(group_photos.get(group_id)),\"photos\")\n",
    "    \n",
    "    except:\n",
    "        print(group_name,\"=> no permission to view the pool\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b62c5769",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "# make 1 list with all photos no matter which group they, and drop duplicates\n",
    "\n",
    "photo_list_groups = []\n",
    "\n",
    "for group in group_photos:\n",
    "    for photo in group_photos[group]:\n",
    "        if (photo not in photo_list_groups) & (photo[0] != USER_OF_INTEREST):\n",
    "            photo_list_groups.append(photo)\n",
    "            \n",
    "print(len(photo_list_groups),\"photos from groups added.\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf12410f",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_groups = pd.DataFrame(photo_list_groups,columns=[\"owner\",\"photo_id\"])\n",
    "save_path = \"./flickr_approach_B_tmp.csv\"\n",
    "df_groups.to_csv(save_path,sep=\"\\t\",index=False)\n",
    "df_groups = pd.read_csv(filename, sep=\"\\t\", dtype=\"str\")\n",
    "df_groups"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9060349",
   "metadata": {},
   "source": [
    "## B) Get comments to the photos\n",
    "\n",
    "Function: **flickr.photos.comments.getList**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "921d881d",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "photo_list_with_comments = []\n",
    "\n",
    "for owner,photo_id in photo_list_groups:\n",
    "\n",
    "    comments = flickr.photos.comments.getList(photo_id = photo_id)[\"comments\"]\n",
    "    \n",
    "    if comments.get(\"comment\") != None:\n",
    "    \n",
    "        for com in comments[\"comment\"]:\n",
    "            if com[\"author\"] == USER_OF_INTEREST:\n",
    "                photo_list_with_comments.append((owner,photo_id,com[\"_content\"]))\n",
    "            \n",
    "print(len(photo_list_with_comments),\"comments were added to the list.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "883e01e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_comments = pd.DataFrame(photo_list_with_comments,columns=[\"owner\",\"photo_id\",\"comment\"])\n",
    "df_comments"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c7dd032",
   "metadata": {},
   "source": [
    "# Step 3: Merge the two lists and save to disk"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ebda0715",
   "metadata": {},
   "source": [
    "**Uncomment what's needed**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d7b7ab2",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df_groups.merge(df_comments,on=[\"owner\",\"photo_id\"], how=\"left\")\n",
    "\n",
    "df.to_csv(\"./data/flickr_approach_B.csv\",sep=\"\\t\",index=False)\n",
    "#df=pd.read_csv(\"./data/flickr_approach_B.csv\",sep=\"\\t\",dtype=\"str\")\n",
    "\n",
    "photo_list_with_comments = [tuple(row) for row in df[[\"owner\",\"photo_id\",\"comment\"]].fillna(\"\").values]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4bf4e6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5d2749a",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(photo_list_with_comments)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ee52dbb",
   "metadata": {},
   "source": [
    "# Step 4: Scrape more photos"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "497a2260",
   "metadata": {},
   "source": [
    "## a) all users from previous search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed35dbb0",
   "metadata": {},
   "outputs": [],
   "source": [
    "users_so_far = list(df.owner.unique())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c13cf54",
   "metadata": {},
   "source": [
    "## b) all users in the groups\n",
    "\n",
    "### flickr.groups.members.getList"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4341233",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "users_from_groups = []\n",
    "\n",
    "for group in groups:\n",
    "    \n",
    "    print(group[1])\n",
    "    \n",
    "    try:\n",
    "        flickr.groups.members.getList(group_id=group[0],per_page=1, page=1)\n",
    "    \n",
    "        for page in range(1,99): # max 99 pages\n",
    "            \n",
    "            len_before = len(users_from_groups)\n",
    "            \n",
    "            res = flickr.groups.members.getList(group_id=group[0],per_page=500, page=page)[\"members\"]\n",
    "            members = res.get(\"member\")\n",
    "            if members != None:\n",
    "                members = [mem[\"nsid\"] for mem in members]\n",
    "                users_from_groups += members\n",
    "                \n",
    "            len_after = len(users_from_groups)\n",
    "            \n",
    "            if len_before == len_after:\n",
    "                break\n",
    "    except:\n",
    "        pass"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "555f2e8b",
   "metadata": {},
   "source": [
    "## c) all users that are contacts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66e38027",
   "metadata": {},
   "outputs": [],
   "source": [
    "# no need for a loop here, n of contacts < 1000\n",
    "res = flickr.contacts.getPublicList(user_id=USER_OF_INTEREST,per_page=1000, page=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ad9fade",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(res[\"contacts\"][\"contact\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91b7e6e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "users_from_contact = [con[\"nsid\"] for con in res[\"contacts\"][\"contact\"]]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db034759",
   "metadata": {},
   "source": [
    "## d) all users with photos that were favourized by the `USER_OF_INTEREST`\n",
    "\n",
    "### flickr.favorites.getList\n",
    "\n",
    "This is also a good opportunity to add more photos that (despite being not commented) can be labeled as 1, since they were faved by the user"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3d74f35",
   "metadata": {},
   "outputs": [],
   "source": [
    "users_from_favs = []\n",
    "faved_photos = []\n",
    "\n",
    "for page in range(1,9): # max 9 pages\n",
    "            \n",
    "    len_before = len(faved_photos)\n",
    "\n",
    "    res = flickr.favorites.getList(user_id=USER_OF_INTEREST,per_page=500, page=page)[\"photos\"]\n",
    "    favs = res.get(\"photo\")\n",
    "    if favs != None:\n",
    "        users = [fav[\"owner\"] for fav in favs]\n",
    "        users_from_favs += users\n",
    "        photos = [(fav[\"owner\"],fav[\"id\"]) for fav in favs]\n",
    "        faved_photos += photos\n",
    "        \n",
    "    len_after = len(faved_photos)\n",
    "\n",
    "    if len_before == len_after:\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f123ae10",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(faved_photos)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a117271d",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_favs = pd.DataFrame(faved_photos,columns=[\"owner\",\"photo_id\"])\n",
    "df_favs[\"fav\"] = True\n",
    "df_favs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e67efc18",
   "metadata": {},
   "outputs": [],
   "source": [
    "# merge df_favs with main file and save to disk\n",
    "\n",
    "df = df.merge(df_favs,on=[\"owner\",\"photo_id\"],how=\"outer\")\n",
    "df.fav = df.fav.fillna(False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca7a4635",
   "metadata": {},
   "source": [
    "**uncomment what's needed**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f8162a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "#df.to_csv(\"./data/flickr_approach_B.csv\",sep=\"\\t\",index=False)\n",
    "#pd.read_csv(\"./data/flickr_approach_B.csv\",sep=\"\\t\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d0f6533",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(users_from_favs)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "edfae93f",
   "metadata": {},
   "source": [
    "**Overall number of photos, that the user approved of (labeled as 1)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d1b21ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(df.loc[pd.notna(df[\"comment\"]) | (df[\"fav\"])])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "554b9e1b",
   "metadata": {},
   "source": [
    "## e) merge the pool of new found users"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb4c9705",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(users_so_far) # what we had already"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e91b799",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(users_from_groups)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "498a5ad0",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(users_from_contact)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41b88b69",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(users_from_favs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "986682ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "new_user_pool = users_so_far + users_from_groups + users_from_contact + users_from_favs\n",
    "new_user_pool = list(dict.fromkeys(new_user_pool)) # to remove duplicates\n",
    "len(new_user_pool)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76972340",
   "metadata": {},
   "source": [
    "## f) get photos from those users\n",
    "\n",
    "### flickr.people.getPhotos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0f022f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "new_photo_pool = []\n",
    "\n",
    "for u in new_user_pool:\n",
    "    try:\n",
    "        res = flickr.people.getPhotos(user_id=u, per_page=500,page=1)[\"photos\"]\n",
    "        pages = res[\"pages\"]\n",
    "    \n",
    "        for page in range(1,pages+1):\n",
    "            res = flickr.people.getPhotos(user_id=u, per_page=500,page=page)[\"photos\"][\"photo\"]\n",
    "            photos = [(photo[\"owner\"],photo[\"id\"]) for photo in res]\n",
    "            new_photo_pool += photos\n",
    "    except:\n",
    "        ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd04a770",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "with open(\"./data/new_photo_pool\", \"w\") as fp:\n",
    "    json.dump(new_photo_pool, fp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52315c11",
   "metadata": {},
   "outputs": [],
   "source": [
    "#with open(\"./data/new_photo_pool\", \"r\") as fp:\n",
    "#    new_photo_pool = json.load(fp)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ab9cb4a",
   "metadata": {},
   "source": [
    "## g) get comments of new photo pool\n",
    "### \n",
    "\n",
    "only for new photos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5dae53c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "edac10a5",
   "metadata": {},
   "source": [
    "# Step X: Download all the images in JPG"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b07a8831",
   "metadata": {},
   "outputs": [],
   "source": [
    "#pip install httplib2\n",
    "#pip install bs4\n",
    "#pip install urllib3\n",
    "\n",
    "import httplib2\n",
    "from bs4 import BeautifulSoup, SoupStrainer\n",
    "import urllib.request\n",
    "opener = urllib.request.build_opener()\n",
    "opener.addheaders = [('User-agent', 'Mozilla/5.0 (Windows NT 6.1; WOW64; rv:56.0) Gecko/20100101 Firefox/56.0')]\n",
    "urllib.request.install_opener(opener)\n",
    "\n",
    "from bs4 import SoupStrainer\n",
    "\n",
    "strainer = SoupStrainer('img', attrs={'class': 'main-photo'})\n",
    "\n",
    "class Extractor():\n",
    "\n",
    "    \n",
    "    def get_links(self, url):\n",
    "\n",
    "        http = httplib2.Http()\n",
    "        response, content = http.request(url)     \n",
    "\n",
    "        images =  BeautifulSoup(content).find_all('img')\n",
    "\n",
    "        image_links=[]\n",
    "\n",
    "        for image in images:\n",
    "            image_links.append(image['src'])\n",
    "        \n",
    "        return image_links\n",
    "    \n",
    "    def get_link(self,url):\n",
    "        \"\"\"\n",
    "        return only main-photo link\n",
    "        \"\"\"\n",
    "        http = httplib2.Http()\n",
    "        response, content = http.request(url)\n",
    "        \n",
    "        image_link =  BeautifulSoup(content, 'html.parser', parse_only=strainer).find()\n",
    "        try:\n",
    "            image_link = \"https:\" + image_link[\"src\"]\n",
    "        except:\n",
    "            image_link = \"\"\n",
    "        \n",
    "        return image_link\n",
    "        \n",
    "    def get_images(self, image_links, filename):\n",
    "        \n",
    "        for link in image_links:\n",
    "                       \n",
    "            image_url = \"https:\" + link    \n",
    "            \n",
    "            try:\n",
    "            \n",
    "                if link[-6:] == \"_n.jpg\":\n",
    "                    local_file, response_headers  = urllib.request.urlretrieve(image_url, filename=\"./img_data/sm/\"+filename)\n",
    "\n",
    "                else:            \n",
    "                    local_file, response_headers  = urllib.request.urlretrieve(image_url, filename=\"./img_data/md/\"+filename)\n",
    "            \n",
    "            except urllib.error.ContentTooShortError as shortError:\n",
    "                print(\"content too short error\")\n",
    "            except urllib.error.HTTPError as e:\n",
    "                print(e)\n",
    "            except urllib.error.URLError as ue:\n",
    "                print(\"failed to download!\")\n",
    "            except socket.timeout as se:\n",
    "                print(\"socket timeout\")\n",
    "            except Exception as ee:\n",
    "                print(ee)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fecef660",
   "metadata": {},
   "source": [
    "## Download\n",
    "\n",
    "incl. check whether or not images are already present in the folder"
   ]
  },
  {
   "cell_type": "raw",
   "id": "56f05fce",
   "metadata": {},
   "source": [
    "%%time\n",
    "\n",
    "import os\n",
    "\n",
    "file_path = \"./img_data/md/\"\n",
    "files = os.listdir(file_path)\n",
    "photo_list_missing = [photo for photo in photo_list_all if photo[1]+\".jpg\" not in files]\n",
    "\n",
    "myextractor = Extractor()\n",
    "\n",
    "baseurl = \"https://www.flickr.com/photos/\"\n",
    "\n",
    "for i in photo_list_missing[:]:\n",
    "    url = f\"\"\"{baseurl}{i[0]}/{i[1]}\"\"\"\n",
    "    filename = i[1] + \".jpg\"\n",
    "    image_links = myextractor.get_links(url)\n",
    "    myextractor.get_images(image_links, filename)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b64ae524",
   "metadata": {},
   "source": [
    "Alternative Approach: get first only the direct links and put them into the pandas DataFrame\n",
    "\n",
    "Estimated time for scraping 16,300 image urls: 6.3h\n",
    "\n",
    "(only the missing urls are actually searched)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49a6e487",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "import os\n",
    "\n",
    "file_path = \"./img_data/md/\"\n",
    "files = os.listdir(file_path)\n",
    "photo_list_missing = [photo for photo in photo_list_all if photo[1]+\".jpg\" not in files]\n",
    "\n",
    "myextractor = Extractor()\n",
    "\n",
    "baseurl = \"https://www.flickr.com/photos/\"\n",
    "\n",
    "for i in df_all.index:\n",
    "    \n",
    "    if pd.isna(df_all.loc[i,\"url\"]):\n",
    "        url = f\"\"\"{baseurl}{df_all.loc[i,\"owner\"]}/{df_all.loc[i,\"photo_id\"]}\"\"\"\n",
    "        image_link = myextractor.get_link(url)\n",
    "        df_all.loc[i,\"url\"] = image_link \n",
    "    else:\n",
    "        ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f49f5d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# save\n",
    "#df_all.to_csv(\"./data/flickr.csv\",sep=\"\\t\",index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d6e3652",
   "metadata": {},
   "source": [
    "# Next Step: pre-process images\n",
    "\n",
    "1) Crop/Scale to same dimensions  \n",
    "2) Drop portrait and square format images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38197acc",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
