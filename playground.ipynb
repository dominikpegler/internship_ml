{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7faf5e1b",
   "metadata": {},
   "source": [
    "Playground\n",
    "---\n",
    "\n",
    "List of regressors and their hyperparameters\n",
    "\n",
    "## Linear Regressors\n",
    "in `sklearn.linear_model`\n",
    "\n",
    "#### `LinearRegression`\n",
    " * Force positive coefficients (e.g. Ordinary least squares vs. Non-Negative least squares): `positive=True`\n",
    "\n",
    "#### `Ridge`\n",
    " * Complexity parameter $\\alpha$: `alpha=.5` (defaults to 1.0)\n",
    " * Force positive coefficients: `positive=True`\n",
    " * Solver method: `solver =` ` 'auto'`, `'svd'`, `'cholesky'`, `'lsqr'`, `'sparse_cg'`, `'sag'`, `'saga'` or `'lbfgs'`\n",
    "\n",
    "#### `RidgeCV`\n",
    " * Same as above with built-in cross validation: defaults to \"leave-one-out\", `cv=10` triggers 10-fold `GridSearchCV` \n",
    " \n",
    "#### `Lasso`\n",
    " * Sparsity parameter $\\alpha$: `alpha=.1` (defaults to 1.0)\n",
    " * Force positive coefficients: `positive=True`\n",
    "\n",
    "\n",
    "#### `LassoCV`\n",
    " * Same as above with built-in cross validation: default 5-fold cross-validation, `cv=10` triggers 10-fold `GridSearchCV` \n",
    " \n",
    "#### `LassoLars`\n",
    " * Lasso with Least Angle Regression \n",
    "\n",
    "#### `LassoLarsCV`\n",
    " * Same as above with built-in cross validation: default 5-fold cross-validation, `cv=10` triggers 10-fold `GridSearchCV` \n",
    " \n",
    "#### `LassoLarsIC`\n",
    "* `Lasso` with information-criteria based model selection\n",
    "\n",
    "#### `MultiTaskLasso`\n",
    "* `Lasso` with y being a 2D array, of shape (n_samples, n_tasks)\n",
    "\n",
    "#### `ElasticNet` & `ElasticNetCV`\n",
    "* ...\n",
    "\n",
    "#### `MultiTaskElasticNet` & `MultiTaskElasticNetCV`\n",
    "* ...\n",
    "* `ElasticNet` with y being a 2D array, of shape (n_samples, n_tasks)\n",
    "\n",
    "#### `OrthogonalMatchingPursuit`\n",
    "* ...\n",
    "\n",
    "#### `BayesianRidge`\n",
    "* ...\n",
    "\n",
    "#### `ARDRegression` (Automatic Relevance Determination)\n",
    "* ...\n",
    "\n",
    "#### `TweedieRegressor` (GenLins)\n",
    "* `power`, `alpha`, `link=` z.B. `'log'`\n",
    "* `power = 1` equivalent to `PoissonRegressor`\n",
    "* `power = 2` equivalent to `GammaRegressor`\n",
    "* `power = 3` Inverse Gaussian distribution.\n",
    "\n",
    "#### `SGDRegressor`\n",
    "* ...\n",
    "\n",
    "#### `Perceptron`\n",
    "* ...\n",
    "\n",
    "#### `PassiveAggressiveRegressor`\n",
    "* ...\n",
    "\n",
    "#### `HuberRegressor` & `TheilSenRegressor` & `RANSACRegressor`\n",
    "* ...\n",
    "\n",
    "#### `QuantileRegressor`\n",
    "* ...\n",
    "\n",
    "#### `PolynomialFeatures`\n",
    "* ..."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4168cbd7-8546-441c-8dca-a2e2198f2137",
   "metadata": {},
   "source": [
    "**Implement XGBRegressor?**\n",
    "\n",
    "```python\n",
    "from xgboost import XGBRegressor\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c2bc125-91bf-4766-aa1f-53b309a520d0",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GroupShuffleSplit\n",
    "from skopt import BayesSearchCV\n",
    "from get_data import get_mindfulness as get_data\n",
    "from regressors import get_regressor\n",
    "from utils import split_train_test\n",
    "from skopt.plots import plot_objective, plot_evaluations, plot_convergence\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "\n",
    "X, y = get_data(\"ffmq-overall\")\n",
    "\n",
    "reg_type = \"rf\"\n",
    "# for reg_type in [\"elasticnet\", \"rf\", \"extratrees\", \"gradientboost\"]:\n",
    "\n",
    "# \"elasticnet\", \"rf\", \"extratrees\", \"gradientboost\"\n",
    "reg, hyperparams_dist = get_regressor(reg_type)\n",
    "\n",
    "outer_cv = GroupShuffleSplit(n_splits=5,\n",
    "                             test_size=0.2,\n",
    "                             random_state=0\n",
    "                             )\n",
    "\n",
    "# iterate over outer CV splitter\n",
    "for i_cv, (i_train, i_test) in enumerate(outer_cv.split(X, y, groups=X.index), start=1):\n",
    "\n",
    "    y_train, y_test = split_train_test(y, i_train, i_test)\n",
    "    X_train, X_test = split_train_test(X, i_train, i_test)\n",
    "\n",
    "    # nested CV with parameter optimization\n",
    "    search_reg = BayesSearchCV(\n",
    "        estimator=reg,\n",
    "        search_spaces=hyperparams_dist,\n",
    "        n_iter=200,  # 200\n",
    "        cv=5,\n",
    "        n_jobs=8,\n",
    "        random_state=0\n",
    "    )\n",
    "\n",
    "    result = search_reg.fit(X_train, y_train.values.ravel())\n",
    "\n",
    "    print(f\"Split {i_cv}:\", result.best_estimator_)\n",
    "    print(\"train score:\", round(result.score(X_train, y_train), 5))\n",
    "    print(\"test  score:\", round(result.score(X_test, y_test), 5))\n",
    "    print(\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e064200-e37e-454d-bf43-6749ce8f5c3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_convergence(search_reg.optimizer_results_)\n",
    "plt.savefig(\"plot_convergence_\"+reg_type+\".png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8665304-91ee-4223-a3ff-9ce7dbee8df9",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_evaluations(search_reg.optimizer_results_[0])\n",
    "plt.savefig(\"plot_evaluations_\"+reg_type+\".png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c7da2df-d16c-41dd-8e24-7e200a070f59",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_objective(search_reg.optimizer_results_[0])\n",
    "plt.savefig(\"plot_objective_\"+reg_type+\".png\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff46ac85-509d-4ead-b929-d81b53ce43fc",
   "metadata": {},
   "source": [
    "predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24cbae95-cbf0-4bfb-82fa-f98bfd391aa3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "y_pred = result.best_estimator_.predict(X)\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "ax.scatter(X,y,alpha=0.3)\n",
    "x = pd.DataFrame(np.linspace(0,5),columns=X.columns)\n",
    "ax.plot(x.values,result.best_estimator_.predict(x))\n",
    "ax.title.set_text(reg_type)\n",
    "try:\n",
    "    plt.text(0.4, 25, f\"y = {result.best_estimator_.coef_[0].round(2)}x + {result.best_estimator_.intercept_.round(2)}\", fontsize=12)\n",
    "except:\n",
    "    ...\n",
    "plt.text(0.4, 22, f\"Best score $RÂ²$ = {result.best_score_.round(3)} ($r$ = {(result.best_score_.round(3)**(1/2)).round(2)})\", fontsize=12)\n",
    "ax.set_ylim(0,30)\n",
    "ax.set_xlim(0,5)\n",
    "fig.savefig(\"predictions_\"+reg_type+\".png\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
