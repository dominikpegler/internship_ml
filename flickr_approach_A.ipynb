{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "23271202",
   "metadata": {},
   "source": [
    "Retrieving information via flickr api\n",
    "---\n",
    "\n",
    "https://www.flickr.com/services/api/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "aa756da1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import flickrapi\n",
    "import webbrowser\n",
    "import json\n",
    "import pandas as pd\n",
    "\n",
    "f = open(\"credentials.json\")\n",
    "creds = json.load(f)\n",
    "API_KEY = creds[\"API_KEY\"]\n",
    "API_SECRET = creds[\"API_SECRET\"]\n",
    "USER_OF_INTEREST = creds[\"USER_OF_INTEREST\"]\n",
    "OWN_USER = creds[\"OWN_USER\"]\n",
    "\n",
    "flickr = flickrapi.FlickrAPI(API_KEY, API_SECRET, format='parsed-json')\n",
    "\n",
    "# Only do this if we don't have a valid token already\n",
    "if not flickr.token_valid(perms='read'):\n",
    "\n",
    "    # Get a request token\n",
    "    flickr.get_request_token(oauth_callback='oob')\n",
    "\n",
    "    # Open a browser at the authentication URL\n",
    "    authorize_url = flickr.auth_url(perms='read')\n",
    "    webbrowser.open_new_tab(authorize_url)\n",
    "\n",
    "    # Get the verifier code from the user\n",
    "    verifier = str(input('Verifier code: '))\n",
    "\n",
    "    # Trade the request token for an access token\n",
    "    flickr.get_access_token(verifier)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7802882e",
   "metadata": {},
   "source": [
    "# Step 1: Get the IDs of commented photos and comments\n",
    "**labeled as 1**\n",
    "\n",
    "**GO STRAIGHT TO STEP 3, IF YOU HAVE THIS INFORMATION ALREADY IN A CSV FILE**\n",
    "\n",
    "## A) Get IDs\n",
    "\n",
    "Function: **flickr.activity.userComments**\n",
    "\n",
    "Command always retrieves **own** comments, not comments by another user "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8bcea3f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "flickr_activity_userComments = {}\n",
    "\n",
    "for page in range(1,99999):\n",
    "\n",
    "    flickr_activity_userComments[page] = flickr.activity.userComments(per_page = 50, page = page)\n",
    "    \n",
    "    if flickr_activity_userComments[page][\"items\"][\"total\"] == 0:\n",
    "        break\n",
    "\n",
    "# number of comments on specific page\n",
    "\n",
    "for page in flickr_activity_userComments.keys():\n",
    "    print(\"page\",page,flickr_activity_userComments[page][\"items\"][\"total\"])\n",
    "\n",
    "# the photos I commented on\n",
    "\n",
    "photo_list = []\n",
    "\n",
    "for page in flickr_activity_userComments.keys():\n",
    "    for item in flickr_activity_userComments[page][\"items\"][\"item\"]:\n",
    "        if (item[\"type\"] == \"photo\") & ((item[\"owner\"],item[\"id\"]) not in photo_list):\n",
    "            photo_list.append((item[\"owner\"],item[\"id\"]))\n",
    "            \n",
    "print(len(photo_list),\"photos were commented.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9060349",
   "metadata": {},
   "source": [
    "## B) Get comments to the photos\n",
    "\n",
    "Function: **flickr.photos.comments.getList**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "921d881d",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "photo_list_with_comments = []\n",
    "\n",
    "for owner,photo_id in photo_list[:]:\n",
    "\n",
    "    comments = flickr.photos.comments.getList(photo_id = photo_id)\n",
    "\n",
    "    for com in comments[\"comments\"][\"comment\"]:\n",
    "        if com[\"author\"] == OWN_USER:\n",
    "            photo_list_with_comments.append((owner,photo_id,com[\"_content\"]))\n",
    "            \n",
    "print(len(photo_list_with_comments),\"comments were added to the list.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "883e01e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(photo_list_with_comments,columns=[\"owner\",\"photo_id\",\"comment\"])\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0cb4057",
   "metadata": {},
   "source": [
    "# Step 2: Get images from user's groups, that were seen, but not commented \n",
    "\n",
    "**labeled as 0**\n",
    "\n",
    "**GO STRAIGHT TO STEP 3, IF YOU HAVE THIS INFORMATION ALREADY IN A CSV FILE**\n",
    "\n",
    "Function: **flickr.people.getPublicGroups**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 365,
   "id": "917312c9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "found 17 groups\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[('14607632@N20', 'Another Planet'),\n",
       " ('2673387@N25', 'APF Magazine Street Photography Group'),\n",
       " ('1572172@N24', 'Beyond Obvious - Photomind'),\n",
       " ('4643780@N22', 'BUDAPESTREET'),\n",
       " ('2019080@N21', 'Color Street Photography 365'),\n",
       " ('2602096@N23', 'EASTREET'),\n",
       " ('472951@N22', 'Fotografi di Strada'),\n",
       " ('474929@N22', 'Fotografía en cuarentena  [nombre de calle]'),\n",
       " ('1840958@N20', 'Gazpacho Photography'),\n",
       " ('94761711@N00', 'HCSP (Hardcore Street Photography)'),\n",
       " ('2746094@N20', 'InQuadra Street Photography Evolution'),\n",
       " ('868185@N20', 'la familia abrazada'),\n",
       " ('2995645@N25', 'Rambles'),\n",
       " ('1363754@N20', 'Small Growers Street Association'),\n",
       " ('2570428@N22', 'Street Minimalism | Color |'),\n",
       " ('1812671@N25', \"Street Photographers' Salon\"),\n",
       " ('1699853@N22', 'un-posed.com')]"
      ]
     },
     "execution_count": 365,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "groups = flickr.people.getPublicGroups(user_id=OWN_USER,invitation_only=True)\n",
    "groups = [(group[\"nsid\"],group[\"name\"]) for group in groups[\"groups\"][\"group\"]]\n",
    "print(\"found\",len(groups),\"groups\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 421,
   "id": "51ef6aa9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Another Planet => 384 photos\n",
      "APF Magazine Street Photography Group => 616 photos\n",
      "Beyond Obvious - Photomind => 1864 photos\n",
      "BUDAPESTREET => 0 photos\n",
      "Color Street Photography 365 => 1405 photos\n",
      "EASTREET => 408 photos\n",
      "Fotografi di Strada => 298 photos\n",
      "Fotografía en cuarentena  [nombre de calle] => 2693 photos\n",
      "Gazpacho Photography => 68 photos\n",
      "HCSP (Hardcore Street Photography) => 3436 photos\n",
      "InQuadra Street Photography Evolution => 1314 photos\n",
      "la familia abrazada => 2783 photos\n",
      "Rambles => 179 photos\n",
      "Small Growers Street Association => 268 photos\n",
      "Street Minimalism | Color | => 1439 photos\n",
      "Street Photographers' Salon => 1257 photos\n",
      "un-posed.com => 1704 photos\n",
      "CPU times: user 779 ms, sys: 71.1 ms, total: 850 ms\n",
      "Wall time: 2min 2s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "group_photos = {}\n",
    "\n",
    "for group_id,group_name in groups:\n",
    "\n",
    "    for page in range (1,9999):\n",
    "\n",
    "        try:\n",
    "            len_before = len(group_photos.get(group_id))\n",
    "        except:\n",
    "            len_before = 0\n",
    "\n",
    "        result = flickr.photos.search(group_id = group_id, per_page=500, page=page)\n",
    "        found_photos = [(photo[\"owner\"],photo[\"id\"]) for photo in result[\"photos\"][\"photo\"] if (photo[\"owner\"],photo[\"id\"]) not in group_photos]\n",
    "\n",
    "        if len_before == 0:\n",
    "            group_photos[group_id] = found_photos\n",
    "        else:\n",
    "            group_photos[group_id] = group_photos.get(group_id) + found_photos\n",
    "\n",
    "        len_after = len(group_photos.get(group_id))\n",
    "\n",
    "        if len_after == len_before:\n",
    "            break\n",
    "\n",
    "    print(group_name,\"=>\",len(group_photos.get(group_id)),\"photos\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 431,
   "id": "67346136",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16116 photos from groups added.\n",
      "\n",
      "CPU times: user 6.3 s, sys: 0 ns, total: 6.3 s\n",
      "Wall time: 6.31 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "# make 1 list with all photos no matter which group they, and drop duplicates\n",
    "\n",
    "photo_list_groups = []\n",
    "\n",
    "for group in group_photos:\n",
    "    for photo in group_photos[group]:\n",
    "        if photo not in photo_list_groups:\n",
    "            photo_list_groups.append(photo)\n",
    "            \n",
    "print(len(photo_list_groups),\"photos from groups added.\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5f3c0e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_groups = pd.DataFrame(photo_list_groups,columns=[\"owner\",\"photo_id\"])\n",
    "df_groups"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c7dd032",
   "metadata": {},
   "source": [
    "# Step 3: Merge the two lists and save to disk"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ebda0715",
   "metadata": {},
   "source": [
    "**Uncomment what's needed**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "0d7b7ab2",
   "metadata": {},
   "outputs": [],
   "source": [
    "#df_all = pd.concat([df,df_groups],sort=False)\n",
    "#df_all = df_all.drop_duplicates([\"owner\",\"photo_id\"],keep=\"first\")\n",
    "\n",
    "#df_all.to_csv(\"./data/flickr_approach_A.csv\",sep=\"\\t\",index=False)\n",
    "#df_all=pd.read_csv(\"./data/flickr_approach_A.csv\",sep=\"\\t\",dtype=\"str\")\n",
    "\n",
    "photo_list_all = [tuple(row) for row in df_all[[\"owner\",\"photo_id\"]].values]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "edac10a5",
   "metadata": {},
   "source": [
    "# Step 4: Download all the images in JPG"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "b07a8831",
   "metadata": {},
   "outputs": [],
   "source": [
    "#pip install httplib2\n",
    "#pip install bs4\n",
    "#pip install urllib3\n",
    "\n",
    "import httplib2\n",
    "from bs4 import BeautifulSoup, SoupStrainer\n",
    "import urllib.request\n",
    "opener = urllib.request.build_opener()\n",
    "opener.addheaders = [('User-agent', 'Mozilla/5.0 (Windows NT 6.1; WOW64; rv:56.0) Gecko/20100101 Firefox/56.0')]\n",
    "urllib.request.install_opener(opener)\n",
    "\n",
    "from bs4 import SoupStrainer\n",
    "\n",
    "strainer = SoupStrainer('img', attrs={'class': 'main-photo'})\n",
    "\n",
    "class Extractor():\n",
    "\n",
    "    \n",
    "    def get_links(self, url):\n",
    "\n",
    "        http = httplib2.Http()\n",
    "        response, content = http.request(url)     \n",
    "\n",
    "        images =  BeautifulSoup(content).find_all('img')\n",
    "\n",
    "        image_links=[]\n",
    "\n",
    "        for image in images:\n",
    "            image_links.append(image['src'])\n",
    "        \n",
    "        return image_links\n",
    "    \n",
    "    def get_link(self,url):\n",
    "        \"\"\"\n",
    "        return only main-photo link\n",
    "        \"\"\"\n",
    "        http = httplib2.Http()\n",
    "        response, content = http.request(url)\n",
    "        \n",
    "        image_link =  BeautifulSoup(content, 'html.parser', parse_only=strainer).find()\n",
    "        try:\n",
    "            image_link = \"https:\" + image_link[\"src\"]\n",
    "        except:\n",
    "            image_link = \"\"\n",
    "        \n",
    "        return image_link\n",
    "        \n",
    "    def get_images(self, image_links, filename):\n",
    "        \n",
    "        for link in image_links:\n",
    "                       \n",
    "            image_url = \"https:\" + link    \n",
    "            \n",
    "            try:\n",
    "            \n",
    "                if link[-6:] == \"_n.jpg\":\n",
    "                    ...\n",
    "                else:            \n",
    "                    local_file, response_headers  = urllib.request.urlretrieve(image_url, filename=\"./img_data/\"+filename)\n",
    "            \n",
    "            except urllib.error.ContentTooShortError as shortError:\n",
    "                print(\"content too short error\")\n",
    "            except urllib.error.HTTPError as e:\n",
    "                print(e)\n",
    "            except urllib.error.URLError as ue:\n",
    "                print(\"failed to download!\")\n",
    "            except socket.timeout as se:\n",
    "                print(\"socket timeout\")\n",
    "            except Exception as ee:\n",
    "                print(ee)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fecef660",
   "metadata": {},
   "source": [
    "## Download\n",
    "\n",
    "incl. check whether or not images are already present in the folder"
   ]
  },
  {
   "cell_type": "raw",
   "id": "56f05fce",
   "metadata": {},
   "source": [
    "%%time\n",
    "\n",
    "import os\n",
    "\n",
    "file_path = \"./img_data/\"\n",
    "files = os.listdir(file_path)\n",
    "photo_list_missing = [photo for photo in photo_list_all if photo[1]+\".jpg\" not in files]\n",
    "\n",
    "myextractor = Extractor()\n",
    "\n",
    "baseurl = \"https://www.flickr.com/photos/\"\n",
    "\n",
    "for i in photo_list_missing[:]:\n",
    "    url = f\"\"\"{baseurl}{i[0]}/{i[1]}\"\"\"\n",
    "    filename = i[1] + \".jpg\"\n",
    "    image_links = myextractor.get_links(url)\n",
    "    myextractor.get_images(image_links, filename)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b64ae524",
   "metadata": {},
   "source": [
    "Alternative Approach: get first only the direct links and put them into the pandas DataFrame\n",
    "\n",
    "Estimated time for scraping 16,300 image urls: 6.3h\n",
    "\n",
    "(only the missing urls are actually searched)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "49a6e487",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<timed exec>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n",
      "\u001b[0;32m/tmp/ipykernel_213990/1815739405.py\u001b[0m in \u001b[0;36mget_link\u001b[0;34m(self, url)\u001b[0m\n\u001b[1;32m     36\u001b[0m         \"\"\"\n\u001b[1;32m     37\u001b[0m         \u001b[0mhttp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhttplib2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mHttp\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 38\u001b[0;31m         \u001b[0mresponse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcontent\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhttp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrequest\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0murl\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     39\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     40\u001b[0m         \u001b[0mimage_link\u001b[0m \u001b[0;34m=\u001b[0m  \u001b[0mBeautifulSoup\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcontent\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'html.parser'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparse_only\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mstrainer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfind\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/py39/lib/python3.9/site-packages/httplib2/__init__.py\u001b[0m in \u001b[0;36mrequest\u001b[0;34m(self, uri, method, body, headers, redirections, connection_type)\u001b[0m\n\u001b[1;32m   1699\u001b[0m                     \u001b[0mcontent\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34mb\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1700\u001b[0m                 \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1701\u001b[0;31m                     (response, content) = self._request(\n\u001b[0m\u001b[1;32m   1702\u001b[0m                         \u001b[0mconn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mauthority\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0muri\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrequest_uri\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmethod\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbody\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mheaders\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mredirections\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcachekey\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1703\u001b[0m                     )\n",
      "\u001b[0;32m~/miniconda3/envs/py39/lib/python3.9/site-packages/httplib2/__init__.py\u001b[0m in \u001b[0;36m_request\u001b[0;34m(self, conn, host, absolute_uri, request_uri, method, body, headers, redirections, cachekey)\u001b[0m\n\u001b[1;32m   1419\u001b[0m             \u001b[0mauth\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrequest\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmethod\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrequest_uri\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mheaders\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbody\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1420\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1421\u001b[0;31m         \u001b[0;34m(\u001b[0m\u001b[0mresponse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcontent\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_conn_request\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrequest_uri\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmethod\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbody\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mheaders\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1422\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1423\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mauth\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/py39/lib/python3.9/site-packages/httplib2/__init__.py\u001b[0m in \u001b[0;36m_conn_request\u001b[0;34m(self, conn, request_uri, method, body, headers)\u001b[0m\n\u001b[1;32m   1371\u001b[0m                 \u001b[0;32mpass\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1372\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1373\u001b[0;31m                 \u001b[0mresponse\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mconn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgetresponse\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1374\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mhttp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclient\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mBadStatusLine\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhttp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclient\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mResponseNotReady\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1375\u001b[0m                 \u001b[0;31m# If we get a BadStatusLine on the first try then that means\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/py39/lib/python3.9/http/client.py\u001b[0m in \u001b[0;36mgetresponse\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1345\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1346\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1347\u001b[0;31m                 \u001b[0mresponse\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbegin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1348\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mConnectionError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1349\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/py39/lib/python3.9/http/client.py\u001b[0m in \u001b[0;36mbegin\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    305\u001b[0m         \u001b[0;31m# read until we get a non-100 response\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    306\u001b[0m         \u001b[0;32mwhile\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 307\u001b[0;31m             \u001b[0mversion\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstatus\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreason\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_read_status\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    308\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mstatus\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0mCONTINUE\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    309\u001b[0m                 \u001b[0;32mbreak\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/py39/lib/python3.9/http/client.py\u001b[0m in \u001b[0;36m_read_status\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    266\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    267\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_read_status\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 268\u001b[0;31m         \u001b[0mline\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreadline\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_MAXLINE\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"iso-8859-1\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    269\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mline\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0m_MAXLINE\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    270\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mLineTooLong\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"status line\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/py39/lib/python3.9/socket.py\u001b[0m in \u001b[0;36mreadinto\u001b[0;34m(self, b)\u001b[0m\n\u001b[1;32m    702\u001b[0m         \u001b[0;32mwhile\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    703\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 704\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_sock\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrecv_into\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    705\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    706\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_timeout_occurred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/py39/lib/python3.9/ssl.py\u001b[0m in \u001b[0;36mrecv_into\u001b[0;34m(self, buffer, nbytes, flags)\u001b[0m\n\u001b[1;32m   1239\u001b[0m                   \u001b[0;34m\"non-zero flags not allowed in calls to recv_into() on %s\"\u001b[0m \u001b[0;34m%\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1240\u001b[0m                   self.__class__)\n\u001b[0;32m-> 1241\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnbytes\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbuffer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1242\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1243\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrecv_into\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbuffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnbytes\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mflags\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/py39/lib/python3.9/ssl.py\u001b[0m in \u001b[0;36mread\u001b[0;34m(self, len, buffer)\u001b[0m\n\u001b[1;32m   1097\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1098\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mbuffer\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1099\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_sslobj\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbuffer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1100\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1101\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_sslobj\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "import os\n",
    "\n",
    "file_path = \"./img_data/\"\n",
    "files = os.listdir(file_path)\n",
    "photo_list_missing = [photo for photo in photo_list_all if photo[1]+\".jpg\" not in files]\n",
    "\n",
    "myextractor = Extractor()\n",
    "\n",
    "baseurl = \"https://www.flickr.com/photos/\"\n",
    "\n",
    "for i in df_all.index:\n",
    "    \n",
    "    if pd.isna(df_all.loc[i,\"url\"]):\n",
    "        url = f\"\"\"{baseurl}{df_all.loc[i,\"owner\"]}/{df_all.loc[i,\"photo_id\"]}\"\"\"\n",
    "        image_link = myextractor.get_link(url)\n",
    "        df_all.loc[i,\"url\"] = image_link \n",
    "    else:\n",
    "        ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "id": "8f49f5d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# save\n",
    "df_all.to_csv(\"./data/flickr_approach_A.csv\",sep=\"\\t\",index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d6e3652",
   "metadata": {},
   "source": [
    "# Next Step: pre-process images\n",
    "\n",
    "1) Crop/Scale to same dimensions  \n",
    "2) Drop portrait and square format images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38197acc",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
